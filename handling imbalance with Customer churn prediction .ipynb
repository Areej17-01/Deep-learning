{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "59badd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count plots\n",
    "#binning\n",
    "#replace with re and normal replace\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3f9a897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7da13b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ee59b3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0a188768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58da2ac",
   "metadata": {},
   "source": [
    "# CHECKING FOR IMBALANCE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c3d136db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "bb74bb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cf7f3b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Exited', ylabel='count'>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "569c525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is clean we just have to encode and standarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "816326c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_or=data.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1e7a9963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "482839ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "encoder = ce.OrdinalEncoder()\n",
    "df_or['Gender'] = encoder.fit_transform(df_or['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c86a55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_or=pd.concat([df_or,pd.get_dummies(df_or['Geography'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0039b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_or=df_or.drop(columns=['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f42abd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       1   42       2       0.00              1          1   \n",
       "1          608       1   41       1   83807.86              1          0   \n",
       "2          502       1   42       8  159660.80              3          1   \n",
       "3          699       1   39       1       0.00              2          0   \n",
       "4          850       1   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0               1        101348.88       1       1        0      0  \n",
       "1               1        112542.58       0       0        0      1  \n",
       "2               0        113931.57       1       1        0      0  \n",
       "3               0         93826.63       0       1        0      0  \n",
       "4               1         79084.10       0       0        0      1  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_or.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558afe0",
   "metadata": {},
   "source": [
    "## BALANCING IMBALANCE BY DIFFERENT METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905d1a8",
   "metadata": {},
   "source": [
    "### UNDERSAMPLING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "50e6bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ones=df_or[df_or['Exited']==1]\n",
    "df_zeros=df_or[df_or['Exited']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a824cbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2037, 13), 7963)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ones.shape,len(df_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6aebe146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "random_integers = np.random.randint(0,len(df_zeros),size=2037)\n",
    "len(random_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7145d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros=df_zeros.iloc[random_integers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ce0a2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.concat([df_zeros,df_ones],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8c2b88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87347.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>99986.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196582.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>689</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>121021.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12182.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>534</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143938.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>658</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84694.49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "1162          615       1   30       9       0.00              1          1   \n",
       "7628          850       2   28       8   99986.98              1          1   \n",
       "564           689       1   38       6  121021.05              1          1   \n",
       "5582          534       2   38       3       0.00              1          0   \n",
       "4146          658       1   24       2       0.00              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "1162               0         87347.82       0       1        0      0  \n",
       "7628               0        196582.55       0       1        0      0  \n",
       "564                1         12182.15       0       0        0      1  \n",
       "5582               0        143938.27       0       1        0      0  \n",
       "4146               1         84694.49       0       1        0      0  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dfbd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2bd0361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4074"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2037+2037"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d85bf9",
   "metadata": {},
   "source": [
    "##### training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c60a5583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87347.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>99986.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196582.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>689</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>121021.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12182.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>534</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143938.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>658</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84694.49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "1162          615       1   30       9       0.00              1          1   \n",
       "7628          850       2   28       8   99986.98              1          1   \n",
       "564           689       1   38       6  121021.05              1          1   \n",
       "5582          534       2   38       3       0.00              1          0   \n",
       "4146          658       1   24       2       0.00              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "1162               0         87347.82       0       1        0      0  \n",
       "7628               0        196582.55       0       1        0      0  \n",
       "564                1         12182.15       0       0        0      1  \n",
       "5582               0        143938.27       0       1        0      0  \n",
       "4146               1         84694.49       0       1        0      0  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e3658fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['Exited'])\n",
    "y=df.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fe77ea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4074, 12), (4074,))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6b3fd7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3259, 12), (3259,))"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7fed2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cols_to_scale = ['Tenure','EstimatedSalary','NumOfProducts','Age','Balance','CreditScore']\n",
    "\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "28a0f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[cols_to_scale] = scaler.fit_transform(X_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "8cdfa751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6719 - accuracy: 0.5759\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6919\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7165\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7303\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7423\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7536\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7604\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7622\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7650\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7693\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7751\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7769\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7742\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7751\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7794\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7766\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7815\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7886\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7806\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7849\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7864\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7852\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7880\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7867\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7907\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7867\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7898\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7886\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7901\n",
      "Epoch 31/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7877\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7895\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7917\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7913\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7947\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7944\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7950\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7938\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7889\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7966\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7947\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7944\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7959\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7975\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7953\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7981\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7996\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7966\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7959\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7966\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7497\n",
      "Test loss: 0.5063\n",
      "Test accuracy: 0.7497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(23, activation='relu', input_shape=(12,)),\n",
    "    keras.layers.Dense(18, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c0757e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.7271 - accuracy: 0.4876\n",
      "Epoch 2/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.5640\n",
      "Epoch 3/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6042\n",
      "Epoch 4/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6238\n",
      "Epoch 5/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6585\n",
      "Epoch 6/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6757\n",
      "Epoch 7/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6793\n",
      "Epoch 8/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6763\n",
      "Epoch 9/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6870\n",
      "Epoch 10/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7119\n",
      "Epoch 11/90\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7100\n",
      "Epoch 12/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7076\n",
      "Epoch 13/90\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7036\n",
      "Epoch 14/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7159\n",
      "Epoch 15/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7226\n",
      "Epoch 16/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7251\n",
      "Epoch 17/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7278\n",
      "Epoch 18/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7389\n",
      "Epoch 19/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7300\n",
      "Epoch 20/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7386\n",
      "Epoch 21/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7343\n",
      "Epoch 22/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7481\n",
      "Epoch 23/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7447\n",
      "Epoch 24/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7505\n",
      "Epoch 25/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7524\n",
      "Epoch 26/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7423\n",
      "Epoch 27/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7465\n",
      "Epoch 28/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7416\n",
      "Epoch 29/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7472\n",
      "Epoch 30/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7484\n",
      "Epoch 31/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7521\n",
      "Epoch 32/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7453\n",
      "Epoch 33/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7570\n",
      "Epoch 34/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7462\n",
      "Epoch 35/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7508\n",
      "Epoch 36/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7564\n",
      "Epoch 37/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7530\n",
      "Epoch 38/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7542\n",
      "Epoch 39/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7551\n",
      "Epoch 40/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7524\n",
      "Epoch 41/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7484\n",
      "Epoch 42/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7539\n",
      "Epoch 43/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7554\n",
      "Epoch 44/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524\n",
      "Epoch 45/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7521\n",
      "Epoch 46/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7493\n",
      "Epoch 47/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7573\n",
      "Epoch 48/90\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7607\n",
      "Epoch 49/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7597\n",
      "Epoch 50/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7576\n",
      "Epoch 51/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7582\n",
      "Epoch 52/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7582\n",
      "Epoch 53/90\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7573\n",
      "Epoch 54/90\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7554\n",
      "Epoch 55/90\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7674\n",
      "Epoch 56/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7637\n",
      "Epoch 57/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7530\n",
      "Epoch 58/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7551\n",
      "Epoch 59/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7558\n",
      "Epoch 60/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7582\n",
      "Epoch 61/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7576\n",
      "Epoch 62/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7650\n",
      "Epoch 63/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7502\n",
      "Epoch 64/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7625\n",
      "Epoch 65/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7564\n",
      "Epoch 66/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7634\n",
      "Epoch 67/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7619\n",
      "Epoch 68/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7604\n",
      "Epoch 69/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7600\n",
      "Epoch 70/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7625\n",
      "Epoch 71/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7665\n",
      "Epoch 72/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7616\n",
      "Epoch 73/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7545\n",
      "Epoch 74/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7573\n",
      "Epoch 75/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7551\n",
      "Epoch 76/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7683\n",
      "Epoch 77/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7656\n",
      "Epoch 78/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7610\n",
      "Epoch 79/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7588\n",
      "Epoch 80/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7524\n",
      "Epoch 81/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7536\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7613\n",
      "Epoch 83/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7680\n",
      "Epoch 84/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7683\n",
      "Epoch 85/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7637\n",
      "Epoch 86/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7634\n",
      "Epoch 87/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7604\n",
      "Epoch 88/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7613\n",
      "Epoch 89/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7607\n",
      "Epoch 90/90\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7705\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7546\n",
      "Test loss: 0.5006\n",
      "Test accuracy: 0.7546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(23, activation='relu', input_shape=(12,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(18, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=90)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "22bb8ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 923us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1965"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert to binary predictions\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "26391f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 96367.1719 - accuracy: 0.2055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[96367.171875, 0.20550000667572021]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fd7facf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.1965\n",
      "Confusion Matrix:\n",
      "[[   0 1607]\n",
      " [   0  393]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1607\n",
      "           1       0.20      1.00      0.33       393\n",
      "\n",
      "    accuracy                           0.20      2000\n",
      "   macro avg       0.10      0.50      0.16      2000\n",
      "weighted avg       0.04      0.20      0.06      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "class_report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba9845",
   "metadata": {},
   "source": [
    "## oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "47328856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ones=df_or[df_or['Exited']==1]\n",
    "df_zeros=df_or[df_or['Exited']==0]\n",
    "import numpy as np\n",
    "\n",
    "random_integers = np.random.randint(0,len(df_ones),size=len(df_zeros))\n",
    "len(random_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "641c4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ones=df_ones.iloc[random_integers]\n",
    "df=pd.concat([df_zeros,df_ones],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "39c452ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177655.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>704</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>133656.91</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145071.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>659</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>123192.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56971.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>683</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>133702.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55582.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>707</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14090.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15926 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "6             822       2   50       7       0.00              2          1   \n",
       "8             501       2   44       4  142051.07              2          0   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "104           670       1   65       1       0.00              1          1   \n",
       "1657          704       1   54       6  133656.91              3          1   \n",
       "9539          659       2   29       6  123192.12              1          1   \n",
       "164           683       2   29       0  133702.89              1          1   \n",
       "9482          707       2   40       1       0.00              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "1                  1        112542.58       0       0        0      1  \n",
       "3                  0         93826.63       0       1        0      0  \n",
       "4                  1         79084.10       0       0        0      1  \n",
       "6                  1         10062.80       0       1        0      0  \n",
       "8                  1         74940.50       0       1        0      0  \n",
       "...              ...              ...     ...     ...      ...    ...  \n",
       "104                1        177655.68       1       0        0      1  \n",
       "1657               0        145071.33       1       0        1      0  \n",
       "9539               1         56971.41       1       1        0      0  \n",
       "164                0         55582.54       1       0        0      1  \n",
       "9482               0         14090.40       1       1        0      0  \n",
       "\n",
       "[15926 rows x 13 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "722694ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15926"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7963+7963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "6902eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(df):    \n",
    "    X=df.drop(columns=['Exited'])\n",
    "    y=df.Exited\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train.shape,y_train.shape\n",
    "\n",
    "\n",
    "\n",
    "    cols_to_scale = ['Tenure','EstimatedSalary','NumOfProducts','Age','Balance','CreditScore']\n",
    "\n",
    "    X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(23, activation='relu', input_shape=(12,)),\n",
    "        #keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(18, activation='relu'),\n",
    "        #keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=90)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  # Convert to binary predictions\n",
    "   \n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test loss: {loss:.4f}\")\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "    class_report = classification_report(y_test, y_pred_binary)\n",
    "    print(\"train accuracy\",model.evaluate(X_train,y_train))\n",
    "\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0edf3696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7001\n",
      "Epoch 2/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7673\n",
      "Epoch 3/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4634 - accuracy: 0.7748\n",
      "Epoch 4/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7783\n",
      "Epoch 5/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4527 - accuracy: 0.7816\n",
      "Epoch 6/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.7860\n",
      "Epoch 7/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.7887\n",
      "Epoch 8/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.7878\n",
      "Epoch 9/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.7905\n",
      "Epoch 10/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.7902\n",
      "Epoch 11/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.7928\n",
      "Epoch 12/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.7924\n",
      "Epoch 13/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4322 - accuracy: 0.7938\n",
      "Epoch 14/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.7976\n",
      "Epoch 15/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.7969\n",
      "Epoch 16/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4265 - accuracy: 0.7984\n",
      "Epoch 17/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4246 - accuracy: 0.7999\n",
      "Epoch 18/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4233 - accuracy: 0.8005\n",
      "Epoch 19/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8001\n",
      "Epoch 20/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8034\n",
      "Epoch 21/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8031\n",
      "Epoch 22/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.8031\n",
      "Epoch 23/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4189 - accuracy: 0.8020\n",
      "Epoch 24/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4175 - accuracy: 0.8039\n",
      "Epoch 25/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8039\n",
      "Epoch 26/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8063\n",
      "Epoch 27/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4143 - accuracy: 0.8066\n",
      "Epoch 28/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8062\n",
      "Epoch 29/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4133 - accuracy: 0.8065\n",
      "Epoch 30/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8065\n",
      "Epoch 31/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8089\n",
      "Epoch 32/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4093 - accuracy: 0.8075\n",
      "Epoch 33/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4087 - accuracy: 0.8103\n",
      "Epoch 34/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.8089\n",
      "Epoch 35/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8097\n",
      "Epoch 36/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4058 - accuracy: 0.8091\n",
      "Epoch 37/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4048 - accuracy: 0.8106\n",
      "Epoch 38/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4045 - accuracy: 0.8118\n",
      "Epoch 39/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4036 - accuracy: 0.8122\n",
      "Epoch 40/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.8113\n",
      "Epoch 41/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4020 - accuracy: 0.8133\n",
      "Epoch 42/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8155\n",
      "Epoch 43/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8122\n",
      "Epoch 44/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4006 - accuracy: 0.8147\n",
      "Epoch 45/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3990 - accuracy: 0.8171\n",
      "Epoch 46/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8161\n",
      "Epoch 47/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3982 - accuracy: 0.8158\n",
      "Epoch 48/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8157\n",
      "Epoch 49/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8162\n",
      "Epoch 50/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8154\n",
      "Epoch 51/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3959 - accuracy: 0.8189\n",
      "Epoch 52/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.8192\n",
      "Epoch 53/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8158\n",
      "Epoch 54/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8177\n",
      "Epoch 55/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3934 - accuracy: 0.8168\n",
      "Epoch 56/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3925 - accuracy: 0.8190\n",
      "Epoch 57/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3921 - accuracy: 0.8180\n",
      "Epoch 58/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3913 - accuracy: 0.8170\n",
      "Epoch 59/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8199\n",
      "Epoch 60/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3915 - accuracy: 0.8215\n",
      "Epoch 61/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3907 - accuracy: 0.8188\n",
      "Epoch 62/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8212\n",
      "Epoch 63/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8215\n",
      "Epoch 64/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3885 - accuracy: 0.8221\n",
      "Epoch 65/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3882 - accuracy: 0.8213\n",
      "Epoch 66/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3879 - accuracy: 0.8218\n",
      "Epoch 67/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3875 - accuracy: 0.8208\n",
      "Epoch 68/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3861 - accuracy: 0.8222\n",
      "Epoch 69/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8206\n",
      "Epoch 70/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3865 - accuracy: 0.8234\n",
      "Epoch 71/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3874 - accuracy: 0.8205\n",
      "Epoch 72/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8239\n",
      "Epoch 73/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3855 - accuracy: 0.8241\n",
      "Epoch 74/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3838 - accuracy: 0.8252\n",
      "Epoch 75/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3839 - accuracy: 0.8242\n",
      "Epoch 76/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8263\n",
      "Epoch 77/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8239\n",
      "Epoch 78/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3835 - accuracy: 0.8267\n",
      "Epoch 79/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3828 - accuracy: 0.8242\n",
      "Epoch 80/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3816 - accuracy: 0.8274\n",
      "Epoch 81/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3811 - accuracy: 0.8283\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3808 - accuracy: 0.8270\n",
      "Epoch 83/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3805 - accuracy: 0.8281\n",
      "Epoch 84/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3811 - accuracy: 0.8248\n",
      "Epoch 85/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3807 - accuracy: 0.8257\n",
      "Epoch 86/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8280\n",
      "Epoch 87/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3791 - accuracy: 0.8279\n",
      "Epoch 88/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3784 - accuracy: 0.8286\n",
      "Epoch 89/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8292\n",
      "Epoch 90/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3784 - accuracy: 0.8292\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 60958.9844 - accuracy: 0.5628\n",
      "Test loss: 60958.9844\n",
      "Test accuracy: 0.5628\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3734 - accuracy: 0.8336\n",
      "train accuracy [0.3733755350112915, 0.8335949778556824]\n",
      "Test accuracy: 0.5628\n",
      "Confusion Matrix:\n",
      "[[ 646  959]\n",
      " [ 434 1147]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.40      0.48      1605\n",
      "           1       0.54      0.73      0.62      1581\n",
      "\n",
      "    accuracy                           0.56      3186\n",
      "   macro avg       0.57      0.56      0.55      3186\n",
      "weighted avg       0.57      0.56      0.55      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8224b7",
   "metadata": {},
   "source": [
    "##### it is overfitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aeff96",
   "metadata": {},
   "source": [
    "### essemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6d31adaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       1   42       2       0.00              1          1   \n",
       "1          608       1   41       1   83807.86              1          0   \n",
       "2          502       1   42       8  159660.80              3          1   \n",
       "3          699       1   39       1       0.00              2          0   \n",
       "4          850       1   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0               1        101348.88       1       1        0      0  \n",
       "1               1        112542.58       0       0        0      1  \n",
       "2               0        113931.57       1       1        0      0  \n",
       "3               0         93826.63       0       1        0      0  \n",
       "4               1         79084.10       0       0        0      1  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_01=pd.concat([df_zeros[:2654],df_ones],axis=0)\n",
    "# df_02=pd.concatdf_zeros[2654:5308],df_ones],axis=0)\n",
    "# df_03=pd.concat([df_zeros[5308:],df_ones],axis=0)\n",
    "df_or.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "2a5694aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_or.drop(columns=['Exited'])\n",
    "y=df_or.Exited\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4719bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>686</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179093.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>632</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>119624.60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>195978.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>559</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>114739.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85891.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>135637.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153080.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>142147.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39488.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>69712.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69381.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>682</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>706.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92220.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>667</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>190227.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97508.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>697</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>147910.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53581.14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "9254          686       2   32       6       0.00              2          1   \n",
       "1561          632       2   42       4  119624.60              2          1   \n",
       "1670          559       2   24       3  114739.92              1          1   \n",
       "6087          561       1   27       9  135637.00              1          1   \n",
       "6669          517       2   56       9  142147.32              1          0   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "5734          768       2   54       8   69712.74              1          1   \n",
       "5191          682       1   58       1       0.00              1          1   \n",
       "5390          735       1   38       1       0.00              3          0   \n",
       "860           667       2   43       8  190227.46              1          1   \n",
       "7270          697       2   51       1  147910.30              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  France  Germany  Spain  Exited  \n",
       "9254               1        179093.26       1        0      0       0  \n",
       "1561               1        195978.86       0        1      0       0  \n",
       "1670               0         85891.02       0        0      1       1  \n",
       "6087               0        153080.40       1        0      0       1  \n",
       "6669               0         39488.04       1        0      0       1  \n",
       "...              ...              ...     ...      ...    ...     ...  \n",
       "5734               1         69381.05       1        0      0       0  \n",
       "5191               1           706.50       1        0      0       0  \n",
       "5390               0         92220.12       1        0      0       1  \n",
       "860                0         97508.04       1        0      0       1  \n",
       "7270               1         53581.14       0        1      0       0  \n",
       "\n",
       "[8000 rows x 13 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.concat([X_train, y_train,],axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "0053440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zeros=train[train[\"Exited\"]==0]\n",
    "df_ones=train[train[\"Exited\"]==1]\n",
    "len(df_zeros)+len(df_ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7551a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_results=[]\n",
    "def essemble(X_train, y_train,X_test,y_test):    \n",
    "    cols_to_scale = ['Tenure','EstimatedSalary','NumOfProducts','Age','Balance','CreditScore']\n",
    "\n",
    "    X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(23, activation='relu', input_shape=(12,)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(18, activation='relu'),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=90)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  # Convert to binary predictions\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test loss: {loss:.4f}\")\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    print(\"train accuracy\",model.evaluate(X_train,y_train))\n",
    "\n",
    "\n",
    "    y_results.append(y_pred_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8c3b2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_t(end,start,X_train, y_train):\n",
    "    train=pd.concat([X_train, y_train],axis=1)\n",
    "    df_zeros=train[train[\"Exited\"]==0]\n",
    "    df_ones=train[train[\"Exited\"]==1]\n",
    "    df_zeros=df_zeros[end:start]\n",
    "    dummy=pd.concat([df_zeros, df_ones],axis=0)\n",
    "    X_train=dummy.drop(columns=['Exited'])\n",
    "    print(len(X_train))\n",
    "    y_train=dummy.Exited\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6edc3402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3764\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>777</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115611.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>579</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>90547.48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18800.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6822</th>\n",
       "      <td>669</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>63723.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181928.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>719</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>122964.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138231.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154767.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25488.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>531</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>114715.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24506.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>117356.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113557.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92220.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>667</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>190227.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97508.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3764 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "6744          777       1   30       4       0.00              2          0   \n",
       "1814          579       2   31       2   90547.48              2          1   \n",
       "6822          669       2   47       0   63723.78              2          1   \n",
       "1011          719       2   35       3  122964.88              1          1   \n",
       "1577          687       1   21       8       0.00              2          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "4555          688       1   35       6       0.00              1          1   \n",
       "769           531       1   63       1  114715.71              1          0   \n",
       "1685          613       1   20       0  117356.19              1          0   \n",
       "5390          735       1   38       1       0.00              3          0   \n",
       "860           667       2   43       8  190227.46              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  France  Germany  Spain  \n",
       "6744               1        115611.97       1        0      0  \n",
       "1814               1         18800.13       0        1      0  \n",
       "6822               1        181928.25       0        1      0  \n",
       "1011               1        138231.70       0        0      1  \n",
       "1577               1        154767.34       0        0      1  \n",
       "...              ...              ...     ...      ...    ...  \n",
       "4555               0         25488.43       0        0      1  \n",
       "769                1         24506.95       1        0      0  \n",
       "1685               0        113557.70       0        1      0  \n",
       "5390               0         92220.12       1        0      0  \n",
       "860                0         97508.04       1        0      0  \n",
       "\n",
       "[3764 rows x 12 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=data_t(4236,6356,X_train, y_train)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "458ed3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3762\n",
      "Epoch 1/90\n",
      "118/118 [==============================] - 1s 2ms/step - loss: 0.7409 - accuracy: 0.5346\n",
      "Epoch 2/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.6034\n",
      "Epoch 3/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6252\n",
      "Epoch 4/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6489\n",
      "Epoch 5/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6752\n",
      "Epoch 6/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6770\n",
      "Epoch 7/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6818\n",
      "Epoch 8/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6879\n",
      "Epoch 9/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7068\n",
      "Epoch 10/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7100\n",
      "Epoch 11/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7137\n",
      "Epoch 12/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7135\n",
      "Epoch 13/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7273\n",
      "Epoch 14/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7251\n",
      "Epoch 15/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7408\n",
      "Epoch 16/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7430\n",
      "Epoch 17/90\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7382\n",
      "Epoch 18/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7408\n",
      "Epoch 19/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7411\n",
      "Epoch 20/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7424\n",
      "Epoch 21/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7493\n",
      "Epoch 22/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7384\n",
      "Epoch 23/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7467\n",
      "Epoch 24/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7554\n",
      "Epoch 25/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7438\n",
      "Epoch 26/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7507\n",
      "Epoch 27/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7629\n",
      "Epoch 28/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7480\n",
      "Epoch 29/90\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7570\n",
      "Epoch 30/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7576\n",
      "Epoch 31/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7618\n",
      "Epoch 32/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7648\n",
      "Epoch 33/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7624\n",
      "Epoch 34/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7610\n",
      "Epoch 35/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7602\n",
      "Epoch 36/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7648\n",
      "Epoch 37/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7618\n",
      "Epoch 38/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7690\n",
      "Epoch 39/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7674\n",
      "Epoch 40/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7648\n",
      "Epoch 41/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7669\n",
      "Epoch 42/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7661\n",
      "Epoch 43/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7610\n",
      "Epoch 44/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7695\n",
      "Epoch 45/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7656\n",
      "Epoch 46/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7727\n",
      "Epoch 47/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7616\n",
      "Epoch 48/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7642\n",
      "Epoch 49/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7685\n",
      "Epoch 50/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7762\n",
      "Epoch 51/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7711\n",
      "Epoch 52/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7754\n",
      "Epoch 53/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7738\n",
      "Epoch 54/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7735\n",
      "Epoch 55/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7759\n",
      "Epoch 56/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7730\n",
      "Epoch 57/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7703\n",
      "Epoch 58/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7783\n",
      "Epoch 59/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7658\n",
      "Epoch 60/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7751\n",
      "Epoch 61/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7706\n",
      "Epoch 62/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7735\n",
      "Epoch 63/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7764\n",
      "Epoch 64/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7632\n",
      "Epoch 65/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7711\n",
      "Epoch 66/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7703\n",
      "Epoch 67/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7727\n",
      "Epoch 68/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7770\n",
      "Epoch 69/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7754\n",
      "Epoch 70/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7836\n",
      "Epoch 71/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7796\n",
      "Epoch 72/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7714\n",
      "Epoch 73/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7727\n",
      "Epoch 74/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7711\n",
      "Epoch 75/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7743\n",
      "Epoch 76/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7709\n",
      "Epoch 77/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7714\n",
      "Epoch 78/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7738\n",
      "Epoch 79/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7799\n",
      "Epoch 80/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7788\n",
      "Epoch 81/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7751\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7802\n",
      "Epoch 83/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7685\n",
      "Epoch 84/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7741\n",
      "Epoch 85/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7799\n",
      "Epoch 86/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7818\n",
      "Epoch 87/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7738\n",
      "Epoch 88/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7788\n",
      "Epoch 89/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7677\n",
      "Epoch 90/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7687\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 79984.0781 - accuracy: 0.1965\n",
      "Test loss: 79984.0781\n",
      "Test accuracy: 0.1965\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7985\n",
      "train accuracy [0.4486368000507355, 0.7985114455223083]\n",
      "3762\n",
      "Epoch 1/90\n",
      "118/118 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5455\n",
      "Epoch 2/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6231\n",
      "Epoch 3/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6454\n",
      "Epoch 4/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6672\n",
      "Epoch 5/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6922\n",
      "Epoch 6/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7004\n",
      "Epoch 7/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7132\n",
      "Epoch 8/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7238\n",
      "Epoch 9/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7297\n",
      "Epoch 10/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7291\n",
      "Epoch 11/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7337\n",
      "Epoch 12/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7432\n",
      "Epoch 13/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7467\n",
      "Epoch 14/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7480\n",
      "Epoch 15/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7483\n",
      "Epoch 16/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7472\n",
      "Epoch 17/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7464\n",
      "Epoch 18/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7507\n",
      "Epoch 19/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7552\n",
      "Epoch 20/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7616\n",
      "Epoch 21/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7570\n",
      "Epoch 22/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7512\n",
      "Epoch 23/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7520\n",
      "Epoch 24/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7624\n",
      "Epoch 25/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7687\n",
      "Epoch 26/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7568\n",
      "Epoch 27/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7586\n",
      "Epoch 28/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7629\n",
      "Epoch 29/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7592\n",
      "Epoch 30/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7645\n",
      "Epoch 31/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7703\n",
      "Epoch 32/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7653\n",
      "Epoch 33/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7658\n",
      "Epoch 34/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7584\n",
      "Epoch 35/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7674\n",
      "Epoch 36/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7687\n",
      "Epoch 37/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7687\n",
      "Epoch 38/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7608\n",
      "Epoch 39/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7706\n",
      "Epoch 40/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7656\n",
      "Epoch 41/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7706\n",
      "Epoch 42/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7645\n",
      "Epoch 43/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7669\n",
      "Epoch 44/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7693\n",
      "Epoch 45/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7698\n",
      "Epoch 46/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7624\n",
      "Epoch 47/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7727\n",
      "Epoch 48/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7719\n",
      "Epoch 49/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7695\n",
      "Epoch 50/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7717\n",
      "Epoch 51/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7730\n",
      "Epoch 52/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7826\n",
      "Epoch 53/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7650\n",
      "Epoch 54/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7698\n",
      "Epoch 55/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7677\n",
      "Epoch 56/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7701\n",
      "Epoch 57/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7703\n",
      "Epoch 58/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7783\n",
      "Epoch 59/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7762\n",
      "Epoch 60/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7735\n",
      "Epoch 61/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7754\n",
      "Epoch 62/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7762\n",
      "Epoch 63/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7749\n",
      "Epoch 64/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7802\n",
      "Epoch 65/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7741\n",
      "Epoch 66/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7762\n",
      "Epoch 67/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7757\n",
      "Epoch 68/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7778\n",
      "Epoch 69/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7738\n",
      "Epoch 71/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7727\n",
      "Epoch 72/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7701\n",
      "Epoch 73/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7749\n",
      "Epoch 74/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7735\n",
      "Epoch 75/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7751\n",
      "Epoch 76/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7775\n",
      "Epoch 77/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7804\n",
      "Epoch 78/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7778\n",
      "Epoch 79/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7823\n",
      "Epoch 80/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7826\n",
      "Epoch 81/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7743\n",
      "Epoch 82/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7775\n",
      "Epoch 83/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7772\n",
      "Epoch 84/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7714\n",
      "Epoch 85/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7770\n",
      "Epoch 86/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7746\n",
      "Epoch 87/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7722\n",
      "Epoch 88/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7754\n",
      "Epoch 89/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7812\n",
      "Epoch 90/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7754\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 122510.9766 - accuracy: 0.1965\n",
      "Test loss: 122510.9766\n",
      "Test accuracy: 0.1965\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7836\n",
      "train accuracy [0.4455413818359375, 0.7836257219314575]\n",
      "3764\n",
      "Epoch 1/90\n",
      "118/118 [==============================] - 1s 2ms/step - loss: 0.7008 - accuracy: 0.5600\n",
      "Epoch 2/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6068\n",
      "Epoch 3/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6363\n",
      "Epoch 4/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6549\n",
      "Epoch 5/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6796\n",
      "Epoch 6/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.6894\n",
      "Epoch 7/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7101\n",
      "Epoch 8/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7043\n",
      "Epoch 9/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7179\n",
      "Epoch 10/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7232\n",
      "Epoch 11/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7357\n",
      "Epoch 12/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7343\n",
      "Epoch 13/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7359\n",
      "Epoch 14/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7399\n",
      "Epoch 15/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7407\n",
      "Epoch 16/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7503\n",
      "Epoch 17/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7447\n",
      "Epoch 18/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7468\n",
      "Epoch 19/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7532\n",
      "Epoch 20/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7420\n",
      "Epoch 21/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7497\n",
      "Epoch 22/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7537\n",
      "Epoch 23/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7535\n",
      "Epoch 24/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7566\n",
      "Epoch 25/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7601\n",
      "Epoch 26/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7511\n",
      "Epoch 27/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7519\n",
      "Epoch 28/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7633\n",
      "Epoch 29/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7630\n",
      "Epoch 30/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7572\n",
      "Epoch 31/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7649\n",
      "Epoch 32/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7617\n",
      "Epoch 33/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7710\n",
      "Epoch 34/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7638\n",
      "Epoch 35/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7651\n",
      "Epoch 36/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7678\n",
      "Epoch 37/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7620\n",
      "Epoch 38/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7649\n",
      "Epoch 39/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7582\n",
      "Epoch 40/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7726\n",
      "Epoch 41/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7670\n",
      "Epoch 42/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7635\n",
      "Epoch 43/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7633\n",
      "Epoch 44/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7721\n",
      "Epoch 45/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7657\n",
      "Epoch 46/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7654\n",
      "Epoch 47/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7585\n",
      "Epoch 48/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7705\n",
      "Epoch 49/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7675\n",
      "Epoch 50/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7683\n",
      "Epoch 51/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7675\n",
      "Epoch 52/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7758\n",
      "Epoch 53/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7641\n",
      "Epoch 54/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7662\n",
      "Epoch 55/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7662\n",
      "Epoch 56/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7675\n",
      "Epoch 57/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7713\n",
      "Epoch 58/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7678\n",
      "Epoch 59/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7728\n",
      "Epoch 60/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7742\n",
      "Epoch 61/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7675\n",
      "Epoch 62/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7742\n",
      "Epoch 63/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7654\n",
      "Epoch 64/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7736\n",
      "Epoch 65/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7694\n",
      "Epoch 66/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7673\n",
      "Epoch 67/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7715\n",
      "Epoch 68/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7744\n",
      "Epoch 69/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7715\n",
      "Epoch 70/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7681\n",
      "Epoch 71/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7707\n",
      "Epoch 72/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7606\n",
      "Epoch 73/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7710\n",
      "Epoch 74/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7697\n",
      "Epoch 75/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7678\n",
      "Epoch 76/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7752\n",
      "Epoch 77/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7715\n",
      "Epoch 78/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7675\n",
      "Epoch 79/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7760\n",
      "Epoch 80/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7694\n",
      "Epoch 81/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7744\n",
      "Epoch 82/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7813\n",
      "Epoch 83/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7620\n",
      "Epoch 84/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7707\n",
      "Epoch 85/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7662\n",
      "Epoch 86/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7670\n",
      "Epoch 87/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7731\n",
      "Epoch 88/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7667\n",
      "Epoch 89/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7686\n",
      "Epoch 90/90\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7646\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 19870.2422 - accuracy: 0.1980\n",
      "Test loss: 19870.2422\n",
      "Test accuracy: 0.1980\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7928\n",
      "train accuracy [0.4556420147418976, 0.7927736639976501]\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip([0,2118,4236],[2118,4236,6356]):\n",
    "    x,y=data_t(i,j,X_train, y_train)\n",
    "    essemble(x,y,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "1e525057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "81e6aa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_results[1][0]+y_results[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "04429eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1607\n",
      "           1       0.20      1.00      0.33       393\n",
      "\n",
      "    accuracy                           0.20      2000\n",
      "   macro avg       0.10      0.50      0.16      2000\n",
      "weighted avg       0.04      0.20      0.06      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Taha PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_final=[]\n",
    "for i in range(len(y_results[0])):\n",
    "    n_ones = y_results[0][i] + y_results[1][i] + y_results[2][i]\n",
    "    \n",
    "    if n_ones>1:\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)\n",
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62152427",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7f7aba1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       1   42       2       0.00              1          1   \n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       2   39       5       0.00              2          1   \n",
       "9996          516       2   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       2   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0                  1        101348.88       1       1        0      0  \n",
       "1                  1        112542.58       0       0        0      1  \n",
       "2                  0        113931.57       1       1        0      0  \n",
       "3                  0         93826.63       0       1        0      0  \n",
       "4                  1         79084.10       0       0        0      1  \n",
       "...              ...              ...     ...     ...      ...    ...  \n",
       "9995               0         96270.64       0       1        0      0  \n",
       "9996               1        101699.77       0       1        0      0  \n",
       "9997               1         42085.58       1       1        0      0  \n",
       "9998               0         92888.52       1       0        1      0  \n",
       "9999               0         38190.78       0       1        0      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0cf804ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    7963\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited']  # Access 'Exited' column using df['Exited']\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert the resampled target variable back to a Pandas Series\n",
    "y_sm_series = pd.Series(y_sm)\n",
    "\n",
    "# Use value_counts() to count the occurrences of each class\n",
    "class_counts = y_sm_series.value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8a8e750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape,y_train.shape\n",
    "\n",
    "\n",
    "\n",
    "cols_to_scale = ['Tenure','EstimatedSalary','NumOfProducts','Age','Balance','CreditScore']\n",
    "\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "28f333b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6878\n",
      "Epoch 2/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7610\n",
      "Epoch 3/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.7739\n",
      "Epoch 4/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7733\n",
      "Epoch 5/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.7791\n",
      "Epoch 6/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.7815\n",
      "Epoch 7/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.7885\n",
      "Epoch 8/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.7858\n",
      "Epoch 9/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7931\n",
      "Epoch 10/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4364 - accuracy: 0.7925\n",
      "Epoch 11/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.7914\n",
      "Epoch 12/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4333 - accuracy: 0.7926\n",
      "Epoch 13/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.7928\n",
      "Epoch 14/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.7972\n",
      "Epoch 15/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.7952\n",
      "Epoch 16/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4269 - accuracy: 0.7951\n",
      "Epoch 17/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4263 - accuracy: 0.7971\n",
      "Epoch 18/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.7995\n",
      "Epoch 19/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.7977\n",
      "Epoch 20/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4228 - accuracy: 0.8025\n",
      "Epoch 21/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.8000\n",
      "Epoch 22/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4209 - accuracy: 0.7988\n",
      "Epoch 23/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4199 - accuracy: 0.8020\n",
      "Epoch 24/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4192 - accuracy: 0.8027\n",
      "Epoch 25/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4187 - accuracy: 0.8041\n",
      "Epoch 26/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4173 - accuracy: 0.8047\n",
      "Epoch 27/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4171 - accuracy: 0.8062\n",
      "Epoch 28/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8027\n",
      "Epoch 29/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4161 - accuracy: 0.8057\n",
      "Epoch 30/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4144 - accuracy: 0.8056\n",
      "Epoch 31/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.8061\n",
      "Epoch 32/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8063\n",
      "Epoch 33/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4124 - accuracy: 0.8079\n",
      "Epoch 34/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8093\n",
      "Epoch 35/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4105 - accuracy: 0.8076\n",
      "Epoch 36/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4106 - accuracy: 0.8097\n",
      "Epoch 37/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4097 - accuracy: 0.8108\n",
      "Epoch 38/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4090 - accuracy: 0.8081\n",
      "Epoch 39/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4085 - accuracy: 0.8095\n",
      "Epoch 40/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4074 - accuracy: 0.8093\n",
      "Epoch 41/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8104\n",
      "Epoch 42/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8100\n",
      "Epoch 43/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4045 - accuracy: 0.8116\n",
      "Epoch 44/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8119\n",
      "Epoch 45/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4045 - accuracy: 0.8105\n",
      "Epoch 46/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8135\n",
      "Epoch 47/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8131\n",
      "Epoch 48/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8144\n",
      "Epoch 49/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4015 - accuracy: 0.8159\n",
      "Epoch 50/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8132\n",
      "Epoch 51/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8137\n",
      "Epoch 52/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3987 - accuracy: 0.8145\n",
      "Epoch 53/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3989 - accuracy: 0.8141\n",
      "Epoch 54/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3979 - accuracy: 0.8148\n",
      "Epoch 55/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8189\n",
      "Epoch 56/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8174\n",
      "Epoch 57/90\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3961 - accuracy: 0.8172\n",
      "Epoch 58/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8173\n",
      "Epoch 59/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3958 - accuracy: 0.8152\n",
      "Epoch 60/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3944 - accuracy: 0.8197\n",
      "Epoch 61/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8188\n",
      "Epoch 62/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3921 - accuracy: 0.8182\n",
      "Epoch 63/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8188\n",
      "Epoch 64/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3916 - accuracy: 0.8191\n",
      "Epoch 65/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3916 - accuracy: 0.8181\n",
      "Epoch 66/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8202\n",
      "Epoch 67/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8184\n",
      "Epoch 68/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3906 - accuracy: 0.8180\n",
      "Epoch 69/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3897 - accuracy: 0.8206\n",
      "Epoch 70/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8203\n",
      "Epoch 71/90\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3887 - accuracy: 0.8188\n",
      "Epoch 72/90\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8207\n",
      "Epoch 73/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3865 - accuracy: 0.8222\n",
      "Epoch 74/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3875 - accuracy: 0.8203\n",
      "Epoch 75/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3867 - accuracy: 0.8222\n",
      "Epoch 76/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3878 - accuracy: 0.8223\n",
      "Epoch 77/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8250\n",
      "Epoch 78/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3852 - accuracy: 0.8235\n",
      "Epoch 79/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 0.8224\n",
      "Epoch 80/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8253\n",
      "Epoch 81/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3848 - accuracy: 0.8226\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3841 - accuracy: 0.8254\n",
      "Epoch 83/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8245\n",
      "Epoch 84/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3836 - accuracy: 0.8260\n",
      "Epoch 85/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3820 - accuracy: 0.8268\n",
      "Epoch 86/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3819 - accuracy: 0.8265\n",
      "Epoch 87/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8271\n",
      "Epoch 88/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3811 - accuracy: 0.8268\n",
      "Epoch 89/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8256\n",
      "Epoch 90/90\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8277\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 107463.2031 - accuracy: 0.4969\n",
      "Test loss: 107463.2031\n",
      "Test accuracy: 0.4969\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3740 - accuracy: 0.8284\n",
      "train accuracy [0.3739559054374695, 0.8284144401550293]\n",
      "Test accuracy: 0.4969\n",
      "Confusion Matrix:\n",
      "[[   4 1601]\n",
      " [   2 1579]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.00      0.00      1605\n",
      "           1       0.50      1.00      0.66      1581\n",
      "\n",
      "    accuracy                           0.50      3186\n",
      "   macro avg       0.58      0.50      0.33      3186\n",
      "weighted avg       0.58      0.50      0.33      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(23, activation='relu', input_shape=(12,)),\n",
    "    #keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(18, activation='relu'),\n",
    "    #keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=90)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "class_report = classification_report(y_test, y_pred_binary)\n",
    "print(\"train accuracy\",model.evaluate(X_train,y_train))\n",
    "\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "983898da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       1   42       2       0.00              1          1   \n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       2   39       5       0.00              2          1   \n",
       "9996          516       2   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       2   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0                  1        101348.88       1       1        0      0  \n",
       "1                  1        112542.58       0       0        0      1  \n",
       "2                  0        113931.57       1       1        0      0  \n",
       "3                  0         93826.63       0       1        0      0  \n",
       "4                  1         79084.10       0       0        0      1  \n",
       "...              ...              ...     ...     ...      ...    ...  \n",
       "9995               0         96270.64       0       1        0      0  \n",
       "9996               1        101699.77       0       1        0      0  \n",
       "9997               1         42085.58       1       1        0      0  \n",
       "9998               0         92888.52       1       0        1      0  \n",
       "9999               0         38190.78       0       1        0      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db4391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6087f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
